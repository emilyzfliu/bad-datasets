{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hZpNTBd2ky_q"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('../')\n",
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "import argparse\n",
        "import gc\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import glob\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "import imageio\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip dataset_release.zip"
      ],
      "metadata": {
        "id": "Sxl5vIoTgJ2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zSgXY3EnUki"
      },
      "source": [
        "## data_util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aTQgQHuBnNFs"
      },
      "outputs": [],
      "source": [
        "face_class = ['background', 'head', 'head***cheek', 'head***chin', 'head***ear', 'head***ear***helix',\n",
        "              'head***ear***lobule', 'head***eye***botton lid', 'head***eye***eyelashes', 'head***eye***iris',\n",
        "              'head***eye***pupil', 'head***eye***sclera', 'head***eye***tear duct', 'head***eye***top lid',\n",
        "              'head***eyebrow', 'head***forehead', 'head***frown', 'head***hair', 'head***hair***sideburns',\n",
        "              'head***jaw', 'head***moustache', 'head***mouth***inferior lip', 'head***mouth***oral comisure',\n",
        "              'head***mouth***superior lip', 'head***mouth***teeth', 'head***neck', 'head***nose',\n",
        "              'head***nose***ala of nose', 'head***nose***bridge', 'head***nose***nose tip', 'head***nose***nostril',\n",
        "              'head***philtrum', 'head***temple', 'head***wrinkles']\n",
        "\n",
        "car_12_class = ['background', 'car_body', 'head light', 'tail light', 'licence plate',\n",
        "                'wind shield', 'wheel', 'door', 'handle' , 'wheelhub', 'window', 'mirror']\n",
        "car_20_class = ['background', 'back_bumper', 'bumper', 'car_body', 'car_lights', 'door', 'fender','grilles','handles',\n",
        "                'hoods', 'licensePlate', 'mirror','roof', 'running_boards', 'tailLight','tire', 'trunk_lids','wheelhub', 'window', 'windshield']\n",
        "\n",
        "\n",
        "car_20_palette =[ 255,  255,  255, # 0 background\n",
        "  238,  229,  102,# 1 back_bumper\n",
        "  0, 0, 0,# 2 bumper\n",
        "  124,  99 , 34, # 3 car\n",
        "  193 , 127,  15,# 4 car_lights\n",
        "  248  ,213 , 42, # 5 door\n",
        "  220  ,147 , 77, # 6 fender\n",
        "  99 , 83  , 3, # 7 grilles\n",
        "  116 , 116 , 138,  # 8 handles\n",
        "  200  ,226 , 37, # 9 hoods\n",
        "  225 , 184 , 161, # 10 licensePlate\n",
        "  142 , 172  ,248, # 11 mirror\n",
        "  153 , 112 , 146, # 12 roof\n",
        "  38  ,112 , 254, # 13 running_boards\n",
        "  229 , 30  ,141, # 14 tailLight\n",
        "  52 , 83  ,84, # 15 tire\n",
        "  194 , 87 , 125, # 16 trunk_lids\n",
        "  225,  96  ,18,  # 17 wheelhub\n",
        "  31 , 102 , 211, # 18 window\n",
        "  104 , 131 , 101# 19 windshield\n",
        "         ]\n",
        "\n",
        "\n",
        "\n",
        "face_palette = [  1.0000,  1.0000 , 1.0000,\n",
        "              0.4420,  0.5100 , 0.4234,\n",
        "              0.8562,  0.9537 , 0.3188,\n",
        "              0.2405,  0.4699 , 0.9918,\n",
        "              0.8434,  0.9329  ,0.7544,\n",
        "              0.3748,  0.7917 , 0.3256,\n",
        "              0.0190,  0.4943 , 0.3782,\n",
        "              0.7461 , 0.0137 , 0.5684,\n",
        "              0.1644,  0.2402 , 0.7324,\n",
        "              0.0200 , 0.4379 , 0.4100,\n",
        "              0.5853 , 0.8880 , 0.6137,\n",
        "              0.7991 , 0.9132 , 0.9720,\n",
        "              0.6816 , 0.6237  ,0.8562,\n",
        "              0.9981 , 0.4692 , 0.3849,\n",
        "              0.5351 , 0.8242 , 0.2731,\n",
        "              0.1747 , 0.3626 , 0.8345,\n",
        "              0.5323 , 0.6668 , 0.4922,\n",
        "              0.2122 , 0.3483 , 0.4707,\n",
        "              0.6844,  0.1238 , 0.1452,\n",
        "              0.3882 , 0.4664 , 0.1003,\n",
        "              0.2296,  0.0401 , 0.3030,\n",
        "              0.5751 , 0.5467 , 0.9835,\n",
        "              0.1308 , 0.9628,  0.0777,\n",
        "              0.2849  ,0.1846 , 0.2625,\n",
        "              0.9764 , 0.9420 , 0.6628,\n",
        "              0.3893 , 0.4456 , 0.6433,\n",
        "              0.8705 , 0.3957 , 0.0963,\n",
        "              0.6117 , 0.9702 , 0.0247,\n",
        "              0.3668 , 0.6694 , 0.3117,\n",
        "              0.6451 , 0.7302,  0.9542,\n",
        "              0.6171 , 0.1097,  0.9053,\n",
        "              0.3377 , 0.4950,  0.7284,\n",
        "              0.1655,  0.9254,  0.6557,\n",
        "              0.9450  ,0.6721,  0.6162]\n",
        "\n",
        "face_palette = [int(item * 255) for item in face_palette]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "car_12_palette =[ 255,  255,  255, # 0 background\n",
        "         124,  99 , 34, # 3 car\n",
        "         193 , 127,  15,# 4 car_lights\n",
        "         229 , 30  ,141, # 14 tailLight\n",
        "        225 , 184 , 161, # 10 licensePlate\n",
        "        104 , 131 , 101,# 19 windshield\n",
        "        52 , 83  ,84, # 15 tire\n",
        "        248  ,213 , 42, # 5 door\n",
        "         116 , 116 , 138,  # 8 handles\n",
        "           225,  96  ,18,  # 17 wheelhub\n",
        "         31 , 102 , 211, # 18 window\n",
        "         142 , 172  ,248, # 11 mirror\n",
        "         ]\n",
        "\n",
        "\n",
        "\n",
        "car_32_palette =[ 255,  255,  255,\n",
        "  238,  229,  102,\n",
        "  0, 0, 0,\n",
        "  124,  99 , 34,\n",
        "  193 , 127,  15,\n",
        "  106,  177,  21,\n",
        "  248  ,213 , 42,\n",
        "  252 , 155,  83,\n",
        "  220  ,147 , 77,\n",
        "  99 , 83  , 3,\n",
        "  116 , 116 , 138,\n",
        "  63  ,182 , 24,\n",
        "  200  ,226 , 37,\n",
        "  225 , 184 , 161,\n",
        "  233 ,  5  ,219,\n",
        "  142 , 172  ,248,\n",
        "  153 , 112 , 146,\n",
        "  38  ,112 , 254,\n",
        "  229 , 30  ,141,\n",
        "  115  ,208 , 131,\n",
        "  52 , 83  ,84,\n",
        "  229 , 63 , 110,\n",
        "  194 , 87 , 125,\n",
        "  225,  96  ,18,\n",
        "  73  ,139,  226,\n",
        "  172 , 143 , 16,\n",
        "  169 , 101 , 111,\n",
        "  31 , 102 , 211,\n",
        "  104 , 131 , 101,\n",
        "  70  ,168  ,156,\n",
        "  183 , 242 , 209,\n",
        "  72  ,184 , 226]\n",
        "\n",
        "bedroom_palette =[ 255,  255,  255,\n",
        "  238,  229,  102,\n",
        "  255, 72, 69,\n",
        "  124,  99 , 34,\n",
        "  193 , 127,  15,\n",
        "  106,  177,  21,\n",
        "  248  ,213 , 42,\n",
        "  252 , 155,  83,\n",
        "  220  ,147 , 77,\n",
        "  99 , 83  , 3,\n",
        "  116 , 116 , 138,\n",
        "  63  ,182 , 24,\n",
        "  200  ,226 , 37,\n",
        "  225 , 184 , 161,\n",
        "  233 ,  5  ,219,\n",
        "  142 , 172  ,248,\n",
        "  153 , 112 , 146,\n",
        "  38  ,112 , 254,\n",
        "  229 , 30  ,141,\n",
        "   238, 229, 12,\n",
        "   255, 72, 6,\n",
        "   124, 9, 34,\n",
        "   193, 17, 15,\n",
        "   106, 17, 21,\n",
        "   28, 213, 2,\n",
        "   252, 155, 3,\n",
        "   20, 147, 77,\n",
        "   9, 83, 3,\n",
        "   11, 16, 138,\n",
        "   6, 12, 24,\n",
        "   20, 22, 37,\n",
        "   225, 14, 16,\n",
        "   23, 5, 29,\n",
        "   14, 12, 28,\n",
        "   15, 11, 16,\n",
        "   3, 12, 24,\n",
        "   22, 3, 11\n",
        "   ]\n",
        "\n",
        "cat_palette = [255,  255,  255,\n",
        "            220, 220, 0,\n",
        "           190, 153, 153,\n",
        "            250, 170, 30,\n",
        "           220, 220, 0,\n",
        "           107, 142, 35,\n",
        "           102, 102, 156,\n",
        "           152, 251, 152,\n",
        "           119, 11, 32,\n",
        "           244, 35, 232,\n",
        "           220, 20, 60,\n",
        "           52 , 83  ,84,\n",
        "          194 , 87 , 125,\n",
        "          225,  96  ,18,\n",
        "          31 , 102 , 211,\n",
        "          104 , 131 , 101\n",
        "          ]\n",
        "\n",
        "def trans_mask_stylegan_20classTo12(mask):\n",
        "    final_mask = np.zeros(mask.shape)\n",
        "    final_mask[(mask != 0)] = 1 # car\n",
        "    final_mask[(mask == 4)] = 2 # head light\n",
        "    final_mask[(mask == 14)] = 5 # tail light\n",
        "    final_mask[(mask == 10)] = 3 # licence plate\n",
        "    final_mask[ (mask == 19)] = 8 # wind shield\n",
        "    final_mask[(mask == 15)] = 6 # wheel\n",
        "    final_mask[(mask == 5)] = 9 # door\n",
        "    final_mask[(mask == 8)] = 10 # handle\n",
        "    final_mask[(mask == 17)] = 11 # wheelhub\n",
        "    final_mask[(mask == 18)] = 7 # window\n",
        "    final_mask[(mask == 11)] = 4 # mirror\n",
        "    return final_mask\n",
        "\n",
        "\n",
        "def trans_mask(mask):\n",
        "    return mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBcbVWEXmjhR"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Jm_FJ4eyk52R"
      },
      "outputs": [],
      "source": [
        "class ImageLabelDataset(Dataset):\n",
        "    def __init__(\n",
        "            self,\n",
        "            img_path_list,\n",
        "            label_path_list, trans,\n",
        "            img_size=(128, 128),\n",
        "    ):\n",
        "        self.label_trans = trans\n",
        "        self.img_path_list = img_path_list\n",
        "        self.label_path_list = label_path_list\n",
        "        self.img_size = img_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_path_list)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        im_path = self.img_path_list[index]\n",
        "        lbl_path = self.label_path_list[index]\n",
        "        im = Image.open(im_path)\n",
        "        try:\n",
        "            lbl = np.load(lbl_path)\n",
        "        except:\n",
        "            lbl = np.array(Image.open(lbl_path))\n",
        "        if len(lbl.shape) == 3:\n",
        "            lbl = lbl[:, :, 0]\n",
        "\n",
        "        lbl = self.label_trans(lbl)\n",
        "        lbl = Image.fromarray(lbl.astype('uint8'))\n",
        "        im, lbl = self.transform(im, lbl)\n",
        "\n",
        "        return im, lbl, im_path\n",
        "\n",
        "    def transform(self, img, lbl):\n",
        "        img = img.resize((self.img_size[0], self.img_size[1]))\n",
        "        lbl = lbl.resize((self.img_size[0], self.img_size[1]), resample=Image.NEAREST)\n",
        "        lbl = torch.from_numpy(np.array(lbl)).long()\n",
        "        img = transforms.ToTensor()(img)\n",
        "        return img, lbl\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2TVjAOHmlMN"
      },
      "source": [
        "## Main Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "H67LIi_Yk-pc"
      },
      "outputs": [],
      "source": [
        "def main(data_path, args, resume, max_data=0, uncertainty_portion=0):\n",
        "    exp_path = args['exp_dir']\n",
        "\n",
        "    base_path = os.path.join(exp_path, \"deeplab_class_%d_checkpoint_%d_filter_out_%f\" %(args['testing_data_number_class'],\n",
        "                                                                                        int(max_data),\n",
        "                                                                                        uncertainty_portion))\n",
        "    if not os.path.exists(base_path):\n",
        "        os.mkdir(base_path)\n",
        "    print(\"Model dir,\", base_path)\n",
        "    num_class = args['testing_data_number_class']\n",
        "\n",
        "\n",
        "    dump_data = []\n",
        "    all_pickle = glob.glob(data_path + '/*.pickle')\n",
        "\n",
        "    used_image = []\n",
        "    for p in all_pickle:\n",
        "        with open(p, 'rb') as f:\n",
        "            curr_dict = pickle.load(f)\n",
        "\n",
        "        for dd in curr_dict:\n",
        "            if not dd['image_name'] in used_image:\n",
        "                used_image.append(dd['image_name'] )\n",
        "                dump_data.append(dd)\n",
        "    if max_data > 0:\n",
        "        dump_data = dump_data[:max_data]\n",
        "    stylegan_images = [data['image_name'] for data in dump_data]\n",
        "    stylegan_labels = [data['image_label_name'] for data in dump_data]\n",
        "\n",
        "    stylegan_images.sort()\n",
        "    stylegan_labels.sort()\n",
        "    if uncertainty_portion > 0:\n",
        "        sort_by_uncertainty = sorted(dump_data, key=lambda k: k['uncertrainty_score'])\n",
        "        filter_out_num = int(len(sort_by_uncertainty) * uncertainty_portion)\n",
        "        sort_by_uncertainty = sort_by_uncertainty[30:-filter_out_num+ 30]\n",
        "        out_idx = range(len(sort_by_uncertainty))\n",
        "        stylegan_images = [sort_by_uncertainty[idx]['image_name'] for idx in out_idx]\n",
        "        stylegan_labels = [sort_by_uncertainty[idx]['image_label_name'] for idx in out_idx]\n",
        "\n",
        "    if args['number_class'] ==  args['testing_data_number_class']:\n",
        "        trans_method = trans_mask\n",
        "    else:\n",
        "        # for testing on ADE-12 only. Since our generated images has 20 labels. Need to merge labels based on testing set.\n",
        "        trans_method = trans_mask_stylegan_20classTo12\n",
        "    assert  len(stylegan_images) == len(stylegan_labels)\n",
        "    print( \"Train data length,\", str(len(stylegan_labels)))\n",
        "\n",
        "    train_data = ImageLabelDataset(img_path_list=stylegan_images,\n",
        "                              label_path_list=stylegan_labels, trans=trans_method,\n",
        "                            img_size=(args['deeplab_res'], args['deeplab_res']))\n",
        "\n",
        "    train_batch = 16\n",
        "\n",
        "    train_data = DataLoader(train_data, batch_size=train_batch, shuffle=True, num_workers=16)\n",
        "    classifier = torchvision.models.segmentation.deeplabv3_resnet101(pretrained=False, progress=False,\n",
        "                                                                     num_classes=num_class, aux_loss=None)\n",
        "    print(classifier.state_dict().keys())\n",
        "    if resume != \"\":\n",
        "        checkpoint = torch.load(resume)\n",
        "        classifier.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        classifier.cuda()\n",
        "    classifier.train()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n",
        "\n",
        "    resnet_transform = torchvision.transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225])\n",
        "\n",
        "\n",
        "    for epoch in range(10):\n",
        "        for i, da, in enumerate(train_data):\n",
        "            if da[0].shape[0] != train_batch:\n",
        "                continue\n",
        "            if i % 10 == 0:\n",
        "                gc.collect()\n",
        "\n",
        "            classifier.train()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            img, mask = da[0], da[1]\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                img = img.cuda()\n",
        "                mask = mask.cuda()\n",
        "\n",
        "            input_img_tensor = []\n",
        "            for b in range(img.size(0)):\n",
        "                if img.size(1) == 4:\n",
        "                    input_img_tensor.append(resnet_transform(img[b][:-1,:,:]))\n",
        "                else:\n",
        "                    input_img_tensor.append(resnet_transform(img[b]))\n",
        "\n",
        "            input_img_tensor = torch.stack(input_img_tensor)\n",
        "\n",
        "            y_pred = classifier(input_img_tensor)['out']\n",
        "            loss = criterion(y_pred, mask)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if i % 10 == 0:\n",
        "                print(epoch, 'epoch', 'iteration', i, 'loss', loss.item())\n",
        "\n",
        "        model_path = os.path.join(base_path, 'deeplab_epoch_' + str(epoch) + '.pth')\n",
        "\n",
        "        print('Save to:', model_path)\n",
        "        torch.save({'model_state_dict': classifier.state_dict()},\n",
        "                   model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nI13_6pxmqcV"
      },
      "source": [
        "## Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByWkIAJHplUg"
      },
      "outputs": [],
      "source": [
        "!unzip model_dir_generated_dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gew6VyJflBU7"
      },
      "outputs": [],
      "source": [
        "args = {\n",
        "    'data_path': 'model_dir/cat_16/samples',\n",
        "    'exp': 'model_dir/cat_16/cat_16.json',\n",
        "    'resume': '',\n",
        "    'max_data': 0,\n",
        "    'uncertainty_portion': 0\n",
        "}\n",
        "\n",
        "opts = json.load(open(args['exp'], 'r'))\n",
        "print(\"Opt\", opts)\n",
        "\n",
        "path =opts['exp_dir']\n",
        "if os.path.exists(path):\n",
        "    pass\n",
        "else:\n",
        "    os.system('mkdir -p %s' % (path))\n",
        "    print('Experiment folder created at: %s' % (path))\n",
        "\n",
        "main(args['data_path'], opts, args['resume'], args['max_data'], args['uncertainty_portion'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vkfnuu6YNK2S"
      },
      "outputs": [],
      "source": [
        "!zip -r 'model_dir_downstream.zip' 'model_dir'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnpWJQcnF6Oz"
      },
      "source": [
        "## Testing utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sFRNZH5fEydQ"
      },
      "outputs": [],
      "source": [
        "def process_image(images):\n",
        "    drange = [-1, 1]\n",
        "    scale = 255 / (drange[1] - drange[0])\n",
        "    images = images * scale + (0.5 - drange[0] * scale)\n",
        "\n",
        "    images = images.astype(int)\n",
        "    images[images > 255] = 255\n",
        "    images[images < 0] = 0\n",
        "\n",
        "    return images.astype(int)\n",
        "\n",
        "def colorize_mask(mask, palette):\n",
        "    # mask: numpy array of the mask\n",
        "\n",
        "    new_mask = Image.fromarray(mask.astype(np.uint8)).convert('P')\n",
        "    new_mask.putpalette(palette)\n",
        "    return np.array(new_mask.convert('RGB'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51r9Z_eEIK4x"
      },
      "source": [
        "## Cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OT8jAhUDIC8T"
      },
      "outputs": [],
      "source": [
        "def cross_validate(cp_path, args):\n",
        "    if args['category'] == 'car':\n",
        "        palette = car_20_palette\n",
        "        ignore_index = -1\n",
        "    elif args['category'] == 'face':\n",
        "        palette = face_palette\n",
        "        ignore_index = -1\n",
        "    elif args['category'] == 'bedroom':\n",
        "        palette = bedroom_palette\n",
        "        ignore_index = 0\n",
        "    elif args['category'] == 'cat':\n",
        "        palette = cat_palette\n",
        "        ignore_index = -1\n",
        "\n",
        "    base_path = os.path.join(cp_path, \"cross_validation\")\n",
        "    if not os.path.exists(base_path):\n",
        "        os.mkdir(base_path)\n",
        "\n",
        "\n",
        "    cps_all = glob.glob(cp_path + \"/*\")\n",
        "\n",
        "    print(cps_all)\n",
        "\n",
        "    cp_list = [data for data in cps_all if '.pth' in data and 'BEST' not in data]\n",
        "    cp_list.sort()\n",
        "    print('CP LIST')\n",
        "    print(cp_list)\n",
        "\n",
        "    ids = range(args['testing_data_number_class'])\n",
        "\n",
        "    data_all = glob.glob(args['testing_path'] + \"/*\")\n",
        "    images = [path for path in data_all if 'npy' not in path]\n",
        "    labels = [path for path in data_all if 'npy' in path]\n",
        "    images.sort()\n",
        "    labels.sort()\n",
        "\n",
        "    vis_data = ImageLabelDataset(img_path_list=images,\n",
        "                                  label_path_list=labels, trans=trans_mask,\n",
        "                                  img_size=(args['deeplab_res'], args['deeplab_res']))\n",
        "    vis_data = DataLoader(vis_data, batch_size=1, shuffle=False, num_workers=0)\n",
        "    vis = []\n",
        "    for j, da, in enumerate(vis_data):\n",
        "        img, mask = da[0], da[1]\n",
        "        img = img.numpy()\n",
        "        img = img * 255.\n",
        "\n",
        "        img = np.transpose(img, (0, 2, 3, 1)).astype(np.uint8)\n",
        "\n",
        "        mask = mask.numpy()\n",
        "\n",
        "        curr_vis = np.concatenate( [img[0], colorize_mask(mask[0], palette)], 0 )\n",
        "        if len(vis) < 50:\n",
        "\n",
        "            vis.append(curr_vis)\n",
        "\n",
        "\n",
        "    vis = np.concatenate(vis, 1)\n",
        "    imageio.imwrite(   os.path.join(base_path, \"testing.jpg\"),\n",
        "                      vis)\n",
        "\n",
        "    fold_num =int( len(images) / 5)\n",
        "    resnet_transform = torchvision.transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225])\n",
        "\n",
        "\n",
        "    classifier = torchvision.models.segmentation.deeplabv3_resnet101(pretrained=False, progress=False,\n",
        "                                                                     num_classes=args['testing_data_number_class'], aux_loss=None)\n",
        "\n",
        "    cross_mIOU = []\n",
        "\n",
        "    for i in range(5):\n",
        "        print(i)\n",
        "        val_image = images[fold_num * i: fold_num *i + fold_num]\n",
        "        val_label = labels[fold_num * i: fold_num *i + fold_num]\n",
        "        test_image = [img for img in images if img not in val_image]\n",
        "        test_label =[label for label in labels if label not in val_label]\n",
        "        print(\"Val Data length,\", str(len(val_image)))\n",
        "        print(\"Testing Data length,\", str(len(test_image)))\n",
        "\n",
        "        val_data = ImageLabelDataset(img_path_list=val_image,\n",
        "                                      label_path_list=val_label, trans=trans_mask,\n",
        "                                      img_size=(args['deeplab_res'], args['deeplab_res']))\n",
        "        val_data = DataLoader(val_data, batch_size=1, shuffle=False, num_workers=0)\n",
        "\n",
        "        test_data = ImageLabelDataset(img_path_list=test_image,\n",
        "                                  label_path_list=test_label, trans=trans_mask,\n",
        "                                img_size=(args['deeplab_res'], args['deeplab_res']))\n",
        "        test_data = DataLoader(test_data, batch_size=1, shuffle=False, num_workers=0)\n",
        "\n",
        "        best_miou = 0\n",
        "        best_val_miou = 0\n",
        "        for resume in cp_list:\n",
        "            print(resume)\n",
        "\n",
        "            checkpoint = torch.load(resume)\n",
        "            classifier.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "\n",
        "            classifier.cuda()\n",
        "            classifier.eval()\n",
        "\n",
        "            unions = {}\n",
        "            intersections = {}\n",
        "            for target_num in ids:\n",
        "                unions[target_num] = 0\n",
        "                intersections[target_num] = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for _, da, in enumerate(val_data):\n",
        "                    print(_)\n",
        "\n",
        "                    img, mask = da[0], da[1]\n",
        "\n",
        "                    if img.size(1) == 4:\n",
        "                        img = img[:, :-1, :, :]\n",
        "\n",
        "                    img = img.cuda()\n",
        "                    mask = mask.cuda()\n",
        "                    input_img_tensor = []\n",
        "                    for b in range(img.size(0)):\n",
        "                        input_img_tensor.append(resnet_transform(img[b]))\n",
        "                    input_img_tensor = torch.stack(input_img_tensor)\n",
        "\n",
        "                    y_pred = classifier(input_img_tensor)['out']\n",
        "                    y_pred = torch.log_softmax(y_pred, dim=1)\n",
        "                    _, y_pred = torch.max(y_pred, dim=1)\n",
        "                    y_pred = y_pred.cpu().detach().numpy()\n",
        "                    mask = mask.cpu().detach().numpy()\n",
        "                    bs = y_pred.shape[0]\n",
        "\n",
        "                    curr_iou = []\n",
        "                    if ignore_index > 0:\n",
        "                        y_pred = y_pred * (mask != ignore_index)\n",
        "                    for target_num in ids:\n",
        "                        y_pred_tmp = (y_pred == target_num).astype(int)\n",
        "                        mask_tmp = (mask == target_num).astype(int)\n",
        "\n",
        "                        intersection = (y_pred_tmp & mask_tmp).sum()\n",
        "                        union = (y_pred_tmp | mask_tmp).sum()\n",
        "\n",
        "                        unions[target_num] += union\n",
        "                        intersections[target_num] += intersection\n",
        "\n",
        "                        if not union == 0:\n",
        "                            curr_iou.append(intersection / union)\n",
        "                mean_ious = []\n",
        "\n",
        "                for target_num in ids:\n",
        "                    mean_ious.append(intersections[target_num] / (1e-8 + unions[target_num]))\n",
        "                mean_iou_val = np.array(mean_ious).mean()\n",
        "\n",
        "                if mean_iou_val > best_val_miou:\n",
        "                    best_val_miou = mean_iou_val\n",
        "                    unions = {}\n",
        "                    intersections = {}\n",
        "                    for target_num in ids:\n",
        "                        unions[target_num] = 0\n",
        "                        intersections[target_num] = 0\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        testing_vis = []\n",
        "                        for _, da, in enumerate(test_data):\n",
        "\n",
        "                            img, mask = da[0], da[1]\n",
        "\n",
        "                            if img.size(1) == 4:\n",
        "                                img = img[:, :-1, :, :]\n",
        "\n",
        "                            img = img.cuda()\n",
        "                            mask = mask.cuda()\n",
        "                            input_img_tensor = []\n",
        "                            for b in range(img.size(0)):\n",
        "                                input_img_tensor.append(resnet_transform(img[b]))\n",
        "                            input_img_tensor = torch.stack(input_img_tensor)\n",
        "\n",
        "                            y_pred = classifier(input_img_tensor)['out']\n",
        "                            y_pred = torch.log_softmax(y_pred, dim=1)\n",
        "                            _, y_pred = torch.max(y_pred, dim=1)\n",
        "                            y_pred = y_pred.cpu().detach().numpy()\n",
        "                            mask = mask.cpu().detach().numpy()\n",
        "\n",
        "                            curr_iou = []\n",
        "                            if ignore_index > 0:\n",
        "                                y_pred = y_pred * (mask != ignore_index)\n",
        "                            for target_num in ids:\n",
        "                                y_pred_tmp = (y_pred == target_num).astype(int)\n",
        "                                mask_tmp = (mask == target_num).astype(int)\n",
        "\n",
        "                                intersection = (y_pred_tmp & mask_tmp).sum()\n",
        "                                union = (y_pred_tmp | mask_tmp).sum()\n",
        "\n",
        "                                unions[target_num] += union\n",
        "                                intersections[target_num] += intersection\n",
        "\n",
        "                                if not union == 0:\n",
        "                                    curr_iou.append(intersection / union)\n",
        "\n",
        "\n",
        "                            img = img.cpu().numpy()\n",
        "                            img =  img * 255.\n",
        "                            img = np.transpose(img, (0, 2, 3, 1)).astype(np.uint8)\n",
        "\n",
        "                            curr_vis = np.concatenate([img[0], colorize_mask(y_pred[0], palette)], 0)\n",
        "                            if len(testing_vis) < 50:\n",
        "                                testing_vis.append(curr_vis)\n",
        "\n",
        "                        testing_vis = np.concatenate(testing_vis, 1)\n",
        "                        imageio.imwrite(os.path.join(base_path, \"testing_round_%d.jpg\" % i),\n",
        "                                          testing_vis)\n",
        "\n",
        "                        test_mean_ious = []\n",
        "\n",
        "                        for target_num in ids:\n",
        "                            test_mean_ious.append(intersections[target_num] / (1e-8 + unions[target_num]))\n",
        "                        best_test_miou = np.array(test_mean_ious).mean()\n",
        "\n",
        "\n",
        "                        print(\"Best IOU ,\", str(best_test_miou), \"CP: \", resume)\n",
        "\n",
        "        cross_mIOU.append(best_test_miou)\n",
        "\n",
        "    print(cross_mIOU)\n",
        "    print(\" cross validation mean:\" , np.mean(cross_mIOU) )\n",
        "    print(\" cross validation std:\", np.std(cross_mIOU))\n",
        "    result = {\"Cross validation mean\": np.mean(cross_mIOU), \"Cross validation std\": np.std(cross_mIOU), \"Cross validation\":cross_mIOU }\n",
        "    with open(os.path.join(cp_path, 'cross.json'), 'w') as f:\n",
        "        json.dump(result, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI6UfIClIM0Y"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9bWaY1y5IHXs"
      },
      "outputs": [],
      "source": [
        "def test(cp_path, args, validation_number=50):\n",
        "    if args['category'] == 'car':\n",
        "        palette = car_20_palette\n",
        "        if args['testing_data_number_class'] == 12:\n",
        "            class_name = car_12_class\n",
        "        elif args['testing_data_number_class'] == 20:\n",
        "            class_name = car_20_class\n",
        "    elif args['category'] == 'face':\n",
        "        palette = face_palette\n",
        "        class_name = face_class\n",
        "\n",
        "    elif args['category'] == 'bedroom':\n",
        "        palette = bedroom_palette\n",
        "    \n",
        "    elif args['category'] == 'cat':\n",
        "        palette = cat_palette\n",
        "\n",
        "    base_path = os.path.join(cp_path, \"validation\")\n",
        "    if not os.path.exists(base_path):\n",
        "        os.mkdir(base_path)\n",
        "\n",
        "\n",
        "    cps_all = glob.glob(cp_path + \"/*\")\n",
        "\n",
        "    cp_list = [data for data in cps_all if '.pth' in data and 'BEST' not in data]\n",
        "\n",
        "    ids = range(args['testing_data_number_class'])\n",
        "\n",
        "    data_all = glob.glob(args['testing_path'] + \"/*\")\n",
        "    images = [path for path in data_all if 'npy' not in path]\n",
        "    labels = [path for path in data_all if 'npy' in path]\n",
        "    images.sort()\n",
        "    labels.sort()\n",
        "\n",
        "    vis_data = ImageLabelDataset(img_path_list=images,\n",
        "                                  label_path_list=labels, trans=trans_mask,\n",
        "                                  img_size=(args['deeplab_res'], args['deeplab_res']))\n",
        "    vis_data = DataLoader(vis_data, batch_size=1, shuffle=False, num_workers=0)\n",
        "    vis = []\n",
        "    for j, da, in enumerate(vis_data):\n",
        "        img, mask = da[0], da[1]\n",
        "        img = img.numpy()\n",
        "        img = img * 255.\n",
        "\n",
        "        img = np.transpose(img, (0, 2, 3, 1)).astype(np.uint8)\n",
        "\n",
        "        mask = mask.numpy()\n",
        "\n",
        "        curr_vis = np.concatenate( [img[0], colorize_mask(mask[0], palette)], 0 )\n",
        "        if len(vis) < 50:\n",
        "\n",
        "            vis.append(curr_vis)\n",
        "\n",
        "    vis = np.concatenate(vis, 1)\n",
        "    imageio.imwrite(   os.path.join(base_path, \"testing_gt.jpg\"),\n",
        "                      vis)\n",
        "\n",
        "\n",
        "    resnet_transform = torchvision.transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225])\n",
        "\n",
        "\n",
        "    classifier = torchvision.models.segmentation.deeplabv3_resnet101(pretrained=False, progress=False,\n",
        "                                                                     num_classes=args['testing_data_number_class'], aux_loss=None)\n",
        "\n",
        "    cross_mIOU = []\n",
        "    if validation_number == 0:\n",
        "        print(\"Report performance on the best checkpoint\")\n",
        "        val_image = images\n",
        "        val_label = labels\n",
        "        test_image = images\n",
        "        test_label = labels\n",
        "    else:\n",
        "        val_image = images[:validation_number]\n",
        "        val_label = labels[:validation_number]\n",
        "        test_image = [img for img in images if img not in val_image]\n",
        "        test_label =[label for label in labels if label not in val_label]\n",
        "    print(\"Val Data length,\", str(len(val_image)))\n",
        "    print(\"Testing Data length,\", str(len(test_image)))\n",
        "\n",
        "    val_data = ImageLabelDataset(img_path_list=val_image,\n",
        "                                  label_path_list=val_label, trans=trans_mask,\n",
        "                                  img_size=(args['deeplab_res'], args['deeplab_res']))\n",
        "    val_data = DataLoader(val_data, batch_size=1, shuffle=False, num_workers=0)\n",
        "\n",
        "    test_data = ImageLabelDataset(img_path_list=test_image,\n",
        "                              label_path_list=test_label, trans=trans_mask,\n",
        "                            img_size=(args['deeplab_res'], args['deeplab_res']))\n",
        "    test_data = DataLoader(test_data, batch_size=1, shuffle=False, num_workers=0)\n",
        "\n",
        "    best_val_miou = 0\n",
        "\n",
        "    cp_list.sort()\n",
        "    for resume in cp_list:\n",
        "        checkpoint = torch.load(resume)\n",
        "        print(checkpoint['model_state_dict'])\n",
        "        classifier.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "\n",
        "        classifier.cuda()\n",
        "        classifier.eval()\n",
        "\n",
        "        unions = {}\n",
        "        intersections = {}\n",
        "        for target_num in ids:\n",
        "            unions[target_num] = 0\n",
        "            intersections[target_num] = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for _, da, in enumerate(val_data):\n",
        "\n",
        "                img, mask = da[0], da[1]\n",
        "\n",
        "                if img.size(1) == 4:\n",
        "                    img = img[:, :-1, :, :]\n",
        "\n",
        "                img = img.cuda()\n",
        "                mask = mask.cuda()\n",
        "                input_img_tensor = []\n",
        "                for b in range(img.size(0)):\n",
        "                    input_img_tensor.append(resnet_transform(img[b]))\n",
        "                input_img_tensor = torch.stack(input_img_tensor)\n",
        "\n",
        "                y_pred = classifier(input_img_tensor)['out']\n",
        "                y_pred = torch.log_softmax(y_pred, dim=1)\n",
        "                _, y_pred = torch.max(y_pred, dim=1)\n",
        "                y_pred = y_pred.cpu().detach().numpy()\n",
        "                mask = mask.cpu().detach().numpy()\n",
        "                bs = y_pred.shape[0]\n",
        "\n",
        "                curr_iou = []\n",
        "\n",
        "                for target_num in ids:\n",
        "                    y_pred_tmp = (y_pred == target_num).astype(int)\n",
        "                    mask_tmp = (mask == target_num).astype(int)\n",
        "\n",
        "                    intersection = (y_pred_tmp & mask_tmp).sum()\n",
        "                    union = (y_pred_tmp | mask_tmp).sum()\n",
        "\n",
        "                    unions[target_num] += union\n",
        "                    intersections[target_num] += intersection\n",
        "\n",
        "                    if not union == 0:\n",
        "                        curr_iou.append(intersection / union)\n",
        "            mean_ious = []\n",
        "\n",
        "            for target_num in ids:\n",
        "                mean_ious.append(intersections[target_num] / (1e-8 + unions[target_num]))\n",
        "            mean_iou_val = np.array(mean_ious).mean()\n",
        "\n",
        "            if mean_iou_val > best_val_miou:\n",
        "                best_val_miou = mean_iou_val\n",
        "                unions = {}\n",
        "                intersections = {}\n",
        "                for target_num in ids:\n",
        "                    unions[target_num] = 0\n",
        "                    intersections[target_num] = 0\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    testing_vis = []\n",
        "                    for _, da, in enumerate(test_data):\n",
        "\n",
        "                        img, mask = da[0], da[1]\n",
        "\n",
        "                        if img.size(1) == 4:\n",
        "                            img = img[:, :-1, :, :]\n",
        "\n",
        "                        img = img.cuda()\n",
        "                        mask = mask.cuda()\n",
        "                        input_img_tensor = []\n",
        "                        for b in range(img.size(0)):\n",
        "                            input_img_tensor.append(resnet_transform(img[b]))\n",
        "                        input_img_tensor = torch.stack(input_img_tensor)\n",
        "\n",
        "                        y_pred = classifier(input_img_tensor)['out']\n",
        "                        y_pred = torch.log_softmax(y_pred, dim=1)\n",
        "                        _, y_pred = torch.max(y_pred, dim=1)\n",
        "                        y_pred = y_pred.cpu().detach().numpy()\n",
        "                        mask = mask.cpu().detach().numpy()\n",
        "\n",
        "                        curr_iou = []\n",
        "\n",
        "                        for target_num in ids:\n",
        "                            y_pred_tmp = (y_pred == target_num).astype(int)\n",
        "                            mask_tmp = (mask == target_num).astype(int)\n",
        "\n",
        "                            intersection = (y_pred_tmp & mask_tmp).sum()\n",
        "                            union = (y_pred_tmp | mask_tmp).sum()\n",
        "\n",
        "                            unions[target_num] += union\n",
        "                            intersections[target_num] += intersection\n",
        "\n",
        "                            if not union == 0:\n",
        "                                curr_iou.append(intersection / union)\n",
        "\n",
        "\n",
        "                        img = img.cpu().numpy()\n",
        "                        img =  img * 255.\n",
        "                        img = np.transpose(img, (0, 2, 3, 1)).astype(np.uint8)\n",
        "\n",
        "                        curr_vis = np.concatenate([img[0], colorize_mask(y_pred[0], palette)], 0)\n",
        "                        if len(testing_vis) < 50:\n",
        "                            testing_vis.append(curr_vis)\n",
        "\n",
        "                    testing_vis = np.concatenate(testing_vis, 1)\n",
        "                    imageio.imwrite(os.path.join(base_path, \"testing.jpg\"),\n",
        "                                      testing_vis)\n",
        "\n",
        "                    test_mean_ious = []\n",
        "\n",
        "                    for j, target_num in enumerate(ids):\n",
        "                        iou = intersections[target_num] / (1e-8 + unions[target_num])\n",
        "                        print(\"IOU for \", target_num, iou)\n",
        "\n",
        "                        test_mean_ious.append(iou)\n",
        "                    best_test_miou = np.array(test_mean_ious).mean()\n",
        "                    print(\"Best IOU ,\", str(best_test_miou), \"CP: \", resume)\n",
        "\n",
        "    print(cross_mIOU)\n",
        "    print(\"Validation mIOU:\" ,best_val_miou)\n",
        "    print(\"Testing mIOU:\" , best_test_miou )\n",
        "\n",
        "    result = {\"Validation\": best_val_miou, \"Testing\":best_test_miou}\n",
        "    with open(os.path.join(cp_path, 'cross.json'), 'w') as f:\n",
        "        json.dump(result, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNtNrS76GTi8"
      },
      "outputs": [],
      "source": [
        "args = {\n",
        "    'exp': 'cat_16.json',\n",
        "    'resume': '.',\n",
        "    'cross_validate': False,\n",
        "    'validation_number': 0\n",
        "}\n",
        "\n",
        "opts = json.load(open(args['exp'], 'r'))\n",
        "print(\"Opt\", opts)\n",
        "\n",
        "path =opts['exp_dir']\n",
        "if os.path.exists(path):\n",
        "    pass\n",
        "else:\n",
        "    os.system('mkdir -p %s' % (path))\n",
        "    print('Experiment folder created at: %s' % (path))\n",
        "\n",
        "\n",
        "if not args['cross_validate']:\n",
        "    test(args['resume'], opts, args['validation_number'])\n",
        "else:\n",
        "    cross_validate(args['resume'], opts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1J7Wts2rHbG-"
      },
      "outputs": [],
      "source": [
        "!zip -r 'cv_baseline.zip' 'cross_validation'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxMmrOWTKCQq"
      },
      "outputs": [],
      "source": [
        "!zip -r 'val_baseline.zip' 'validation'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "98fPf3HOmZ5w"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "datasetgan_downstream.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}